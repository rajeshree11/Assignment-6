# -*- coding: utf-8 -*-
"""EAI6010_Assignment6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FlbnqLtX4jL9faHai92tNBazH0i5fqqd
"""

import streamlit as st
import pandas as pd
import spacy
from textblob import TextBlob

# Use spaCy's blank English model to avoid installation issues
nlp = spacy.blank("en")

# Streamlit App
st.title("Airbnb Listing NLP Analyzer")

# File uploader
uploaded_file = st.file_uploader("Upload Airbnb Listings CSV", type=["csv", "gz"])

if uploaded_file:
    if uploaded_file.name.endswith('.gz'):
        df = pd.read_csv(uploaded_file, compression='gzip')
    else:
        df = pd.read_csv(uploaded_file)

    if "description" in df.columns:
        text_column = "description"
    else:
        text_column = st.selectbox("Select the column with property descriptions", df.columns)

    # Drop missing values to ensure matching lengths
    df = df.dropna(subset=[text_column]).reset_index(drop=True)

    # Process descriptions
    if st.button("Analyze Descriptions"):
        entity_results = []
        sentiment_results = []

        for text in df[text_column]:
            doc = nlp(text)  # Tokenize text using spaCy's blank model
            entities = [(ent.text, ent.label_) for ent in doc.ents]  # No named entity recognition (NER)
            sentiment = TextBlob(text).sentiment.polarity  # Sentiment analysis

            entity_results.append(entities)
            sentiment_results.append(sentiment)

        # Ensure the lengths match before assigning to the DataFrame
        df["Entities"] = entity_results
        df["Sentiment"] = sentiment_results

        st.write("### Processed Data:")
        st.dataframe(df[["description", "Entities", "Sentiment"]])

        csv_data = df.to_csv(index=False).encode('utf-8')
        st.download_button("Download Processed Data", csv_data, "airbnb_nlp_results.csv", "text/csv")

st.write("Upload an Airbnb dataset with textual property descriptions to analyze entities and sentiment!")
